#DFS-NONRECURSIVE
import networkx as nx
import matplotlib.pyplot as plt
import pandas as pd
def dfsnonrecursive(graph, startnode):
    visited = set()
    stack = [(startnode,None)]
    torder = []
    edges = []

    while stack:
        node, parent = stack.pop()

        if node not in visited:
            visited.add(node)
            torder.append(node)

            if parent is not None:
                edges.append((parent, node))
            neighbors = list (graph.neighbors(node))
            for neighbor in neighbors:
                if neighbor not in visited:
                    stack.append((neighbor , node))
    return (torder,edges)
data = pd.read_csv('dfs.txt')
graph = nx.from_pandas_edgelist(data, 'source', 'target', create_using=nx.Graph())
startnode = list(graph.nodes())[0]
torder_non_recursive, edges_non_recursive = dfsnonrecursive(graph, startnode)
# torder_recursive,edges_recursive = dfsrecursive(graph, startnode)
print("Order:", torder_non_recursive)
print("Edges:", edges_non_recursive)
pos = nx.spring_layout(graph)  # Layout for the original graph
nx.draw(graph, pos, with_labels=True)
plt.title("Original Graph")
T1 = nx.Graph()  # Create a new graph for DFS tree
T1.add_edges_from(edges_non_recursive)  # Add edges from the non-recursive DFS traversal
pos1 = nx.spring_layout(T1)  # Layout for the DFS tree
nx.draw(T1, pos1, with_labels=True )
plt.title("DFS Tree (Non-recursive)")

-----------------------------------------------------------------
#DFS-RECURSIVE
import networkx as nx
import matplotlib.pyplot as plt
import pandas as pd
def dfsrecursive(graph, node, visited=None, torder=None, edges=None):
    if visited is None:
        visited = set()
    if torder is None:
        torder = []
    if edges is None:
        edges = []

    visited.add(node)
    torder.append(node)

    for neighbour in graph.neighbors(node):
        if neighbour not in visited:
            edges.append((node,neighbour))
            dfsrecursive(graph,neighbour,visited,torder,edges)
    return torder,edges
data = pd.read_csv('dfs.txt')
graph_recursive = nx.from_pandas_edgelist(data,'source','target',create_using = nx.Graph())
node = list(graph_recursive.nodes())[0]
torder_recursive, edges_recursive = dfsrecursive(graph_recursive,node)
print("Order:", torder_recursive)
print("Edges:", edges_recursive)
pos_recursive = nx.spring_layout(graph_recursive)
nx.draw(graph_recursive,pos_recursive, with_labels=True)
T2=nx.Graph()
T2.add_edges_from(edges_recursive)
pos2 = nx.spring_layout(T2)
nx.draw(T2,pos2, with_labels=True)


--------------------------------------------------
#BREADTH FIRST SEARCH
from collections import deque

def breadthfs(graph, startnode):
    visited = set()
    queue = deque([(startnode, None)])
    torder = []
    edges = []

    while queue:
        node, parent = queue.popleft()
        if node not in visited:
            visited.add(node)
            torder.append(node)
            if parent is not None:
                edges.append((parent,node))

            for neighbour in graph.neighbors(node):
                if neighbour not in visited:
                    queue.append((neighbour,node))

    return torder, edges

data = pd.read_csv('dfs.txt')
graph_BFS = nx.from_pandas_edgelist(data,'source','target',create_using=nx.Graph())
startnode=list(graph_BFS.nodes())[0]
torder_BFS, edges_BFS = breadthfs(graph_BFS,startnode)
print("Order:", torder_BFS)
print("Edges:", edges_BFS)

pos_BFS = nx.spring_layout(graph_BFS)
nx.draw(graph_BFS,pos_BFS, with_labels=True)

T3=nx.Graph()
T3.add_edges_from(edges_recursive)
posBFS = nx.spring_layout(T3)
nx.draw(T3,posBFS, with_labels=True)

------------------------------------------------------

# BEST FIRST SEARCH
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from queue import PriorityQueue

df = pd.read_csv()
G = nx.from_pandas_edgelist(df,'Source','Target',edge_attr='Weight',create_using=nx.Graph()) # Undirected weighted
#G = nx.from_pandas_edgelist(df, 'Source', 'Target', create_using=nx.DiGraph()) #DIRECTED,UNWEIGHTED 
#G = nx.from_pandas_edgelist(df, 'Source', 'Target', create_using=nx.Graph()) #UNDIRECTED,UNWEIGHTED 
#G = nx.from_pandas_edgelist(df, 'Source', 'Target', edge_attr='Weight', create_using=nx.DiGraph())  #DIRECTED,WEIGHTED 

heuristic={}
print("Enter heuristic values:")
for node in G.nodes():
    heuristic[node]=float(input(f"h[{node}] = "))

def best_first_search(G, heuristic, start, goal):
    visited=set()
    pq=PriorityQueue()
    pq.put((heuristic[start], start, [start]))
    while not pq.empty():
        h,node,path=pq.get()
        if node==goal:
            return path
        if node not in visited:
            visited.add(node)
            for neighbour in G.neighbors(node):
                if neighbour not in visited:
                    pq.put((heuristic[node],neighbour,path+[neighbour]))
    return []

start = input("Enter start node: ")
goal = input("Enter goal node: ")

path = best_first_search(G, heuristic, start, goal)
if path:
    print("Path found:","->".join(path))
else : 
    print("not found path")

#visualization:
plt.figure(figsize=(8,6))
pos = nx.spring_layout(G, seed=42)

# draw base graph
nx.draw(G, pos,
        with_labels=False,
        node_size=700,
        node_color='lightblue',
        arrows=True)

# edge weights (if any)
if 'Weight' in df.columns:
    labels = nx.get_edge_attributes(G, 'Weight')
    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels, font_size=9)

# node labels: name + heuristic
node_labels = {}
for n in G.nodes():
    node_labels[n] = f"{n}\nh={heuristic[n]:.1f}"
nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=10)

# highlight the path
if path:
    nx.draw_networkx_edges(G, pos,
        edgelist=list(zip(path, path[1:])),
        edge_color='red', width=2)

plt.title("Best-First Search (Path in red)")
plt.axis('off')
plt.tight_layout()
plt.show()

-------------------------------------------------------
#A* ALGO
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from queue import PriorityQueue

# Load the graph
df = pd.read_csv('undirected_weighted_graph.csv')  # Ensure CSV path is correct
G = nx.from_pandas_edgelist(df, 'Source', 'Target', edge_attr='Weight', create_using=nx.Graph())
#G = nx.from_pandas_edgelist(df, 'Source', 'Target', create_using=nx.DiGraph()) #DIRECTED,UNWEIGHTED 
#G = nx.from_pandas_edgelist(df, 'Source', 'Target', create_using=nx.Graph()) #UNDIRECTED,UNWEIGHTED 
#G = nx.from_pandas_edgelist(df, 'Source', 'Target', edge_attr='Weight', create_using=nx.DiGraph())  #DIRECTED,WEIGHTED 
# Take Heuristic Values from the User
heuristic = {}
print("Enter heuristic values:")
for node in G.nodes():
    heuristic[node] = float(input(f"h[{node}] = "))

# A* Search Algorithm Function
def a_star_search(G, heuristic, start, goal):
    # g(n) - actual cost, h(n) - heuristic cost
    g = {node: float('inf') for node in G.nodes()}  # g(n) - cost from start to node
    g[start] = 0
    pq = PriorityQueue()
    pq.put((heuristic[start], start, [start]))  # f(n) = h(n) + g(n), start with f = h(start)
    visited = set()

    while not pq.empty():
        f, node, path = pq.get()

        if node == goal:
            return path  # Return the path if the goal is reached

        if node not in visited:
            visited.add(node)
            for neighbor in G.neighbors(node):
                # Calculate the g(n) for each neighbor
                tentative_g = g[node] + G[node][neighbor]['Weight']
                if tentative_g < g[neighbor]:  # If a shorter path is found
                    g[neighbor] = tentative_g
                    f_cost = g[neighbor] + heuristic[neighbor]  # f(n) = g(n) + h(n)
                    pq.put((f_cost, neighbor, path + [neighbor]))

    return []  # Return empty list if no path found

# Take Start and Goal Input from User
start = input("Enter start node: ")
goal = input("Enter goal node: ")

# Run A* Search
path = a_star_search(G, heuristic, start, goal)

# Output Path
if path:
    print("Path found:", " -> ".join(path))
else:
    print("No path found.")

# Visualization
plt.figure(figsize=(8,6))
pos = nx.spring_layout(G, seed=42)

# Draw base graph
nx.draw(G, pos,
        with_labels=False,
        node_size=700,
        node_color='lightblue',
        arrows=True)

# Edge weights (if any)
if 'Weight' in df.columns:
    labels = nx.get_edge_attributes(G, 'Weight')
    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels, font_size=9)

# Node labels: name + heuristic
node_labels = {}
for n in G.nodes():
    node_labels[n] = f"{n}\nh={heuristic[n]:.1f}"
nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=10)

# Highlight the path
if path:
    nx.draw_networkx_edges(G, pos,
        edgelist=list(zip(path, path[1:])),
        edge_color='red', width=2)

plt.title("A* Algorithm (Path in red)")
plt.axis('off')
plt.tight_layout()
plt.show()

---------------------------------------------------------
#fuxxy set
n1 = int(input("Enter number of elements in A:"))
#stored in dicts-- key are elemnts of fuzzy set and values are their membership values
A={}
for i in range (n1):
    k = input("Enter key:")
    v = float(input("Enter its value"))
    A[k]=v

n2 = int(input("Enter number of elements in B:"))
B={}
for j in range (n2):
    k = input("Enter key:")
    v = float(input("Enter its value"))
    B[k]=v
n3 = int(input("Enter number of elements in C:"))
C={}
for j in range (n3):
    k = input("Enter key:")
    v = float(input("Enter its value"))
    C[k]=v
print(A)
print(B)
print(C)
union = {}
for k in set(A) | set(B) | set(C):
    if k in A and k in B and k in C:
        union[k]=max(A[k],B[k],C[k])
    elif k in A:
        union[k]=A[k]
    elif k in B:
        union[k]=B[k]
    elif k in C:
        union[k]=C[k]
        
intersection = {}
for k in set(A) & set(B) & set(C):
    intersection[k] = min(A[k], B[k],C[k])  

complement_A = {}
for k, v in A.items():
    complement_A[k] = round(1 - v, 2)

complement_B = {}
for k, v in B.items():
    complement_B[k] = round(1-v,2)
    
complement_C = {}
for k, v in C.items():
    complement_C[k] = round(1-v,2)

print("\nUnion:", union)
print("\nIntersection:", intersection)
print("\nComplement of A:", complement_A)
print("\nComplement of B:", complement_B)
print("\nComplement of C:", complement_C)

#subset
subset_A = True
for k in A:
    if k in B and A[k] > B[k]:
        subset_A = False
        break

subset_B = True
for k in B:
    if k in A and B[k] > A[k]:
        subset_B = False
        break

print("\nA is subset of B:", subset_A)
print("B is subset of A:", subset_B)


print("\nDe Morgan’s Law")

# Complement of Intersection (LHS)
LHS = {}
for k, v in intersection.items():
    LHS[k] = round(1 - v, 2)

# Union of Complements (RHS)
RHS = {}
for k in set(A) | set(B):
    if k in A and k in B:
        RHS[k] = max(complement_A[k], complement_B[k])
    elif k in A:
        RHS[k] = complement_A[k]
    else:
        RHS[k] = complement_A[k]

print("LHS (Complement of Intersection):", LHS)
print("RHS (Union of Complements):", RHS)
print("De Morgan’s Law holds:", LHS == RHS)

# Complement of Union (LHS)
LHS = {}
for k, v in union.items():
    LHS[k] = round(1 - v, 2)

# Intersection of Complements (RHS)
RHS = {}
for k in set(A) & set(B):
    if k in A and k in B:
        RHS[k] = min(complement_A[k], complement_B[k])
    elif k in A:
        RHS[k] = complement_A[k]
    else:
        RHS[k] = complement_A[k]

print("LHS (Complement of Union):", LHS)
print("RHS (Intersection of Complements):", RHS)
print("De Morgan’s Law holds:", LHS == RHS)

----------------------------------------------------
#multilayer perceptron- N binary inputs, two hidden layers and one binary output

import numpy as np

n = int(input("Enter the number of inputs: "))
total_cases = 2**n
#generate all combinations of inputs
inputs = np.array([[int(x) for x in format(i,f'0{n}b')] for i in range(total_cases)])

expected_outputs = []
print("\nEnter the expected output for each combination:")
for row in inputs:
    output = int(input(f"Input: {row} -"))
    expected_outputs.append(output)
expected_outputs = np.array(expected_outputs)

# for 2 outputs
# expected_outputs = []
# print("\nEnter the expected 2 outputs for each combination (separated by space):")
# for row in inputs:
#     output = list(map(int, input(f"Input: {row} - ").split()))
#     expected_outputs.append(output)
# expected_outputs = np.array(expected_outputs)

#bias entered for each layer
bias1 = float(input("\nEnter bias1: ")) #Hidden Layer 1
bias2 = float(input("Enter bias2: ")) #Hidden Layer 2 
bias3 = float(input("Enter bias3: ")) #Output Layer 

#hidden layer sizes
hidden1_neurons = n
hidden2_neurons = n


training_step = 0
while True:
    training_step += 1
    found = True
    outputs = []

    w1 = np.round(np.random.uniform(-1.5, 1.5, (n,hidden1_neurons)),4)
    w2 = np.round(np.random.uniform(-1.5, 1.5, (hidden1_neurons, hidden2_neurons)), 4)
    w3 = np.round(np.random.uniform(-1.5, 1.5, hidden2_neurons), 4)

    for i in range(total_cases):
        net1 = np.dot(inputs[i],w1)+bias1
        net2 = np.dot(net1,w2)+bias2
        net3 = np.dot(net2,w3)+bias3

        output = 1 if net3>=0 else 0
        outputs.append(output)

        if output!=expected_outputs[i]:
            found= False
            break # try again with random weights
    if found:
        break

print(f"\nNeural Network with {n} inputs, one output and 2 hidden layers")
print(f"\nOutput matched expected results in {training_step} training step(s)\n")

print("Weight 1 matrix :")
print(w1)
print("\nWeight 2 matrix:")
print(w2)
print("\nWeight 3 matrix:")
print(w3)

for i in range(total_cases):
    print(f"Input: {inputs[i]} \t Expected: {expected_outputs[i]} \t Output: {outputs[i]}")

----------------------------------------------------------------
# Multilayer Perceptron - 4 inputs, 1 hidden layer, 2 outputs
import numpy as np

n = 4  # fixed 4 inputs
total_cases = 2**n

# generate all input combinations
inputs = np.array([[int(x) for x in format(i,f'04b')] for i in range(total_cases)])

expected_outputs = []
print("\nEnter the expected 2 outputs for each combination (separated by space):")
for row in inputs:
    output = list(map(int, input(f"Input: {row} - ").split()))
    expected_outputs.append(output)
expected_outputs = np.array(expected_outputs)

# biases for hidden layer and output layer
bias1 = float(input("\nEnter bias1 (for hidden layer): "))
bias2 = float(input("Enter bias2 (for output layer): "))

# hidden layer size
hidden_neurons = 4
output_neurons = 2

training_step = 0
while True:
    training_step += 1
    found = True
    outputs = []

    w1 = np.round(np.random.uniform(-1.5, 1.5, (n, hidden_neurons)), 4)  # input -> hidden
    w2 = np.round(np.random.uniform(-1.5, 1.5, (hidden_neurons, output_neurons)), 4)  # hidden -> output

    for i in range(total_cases):
        net1 = np.dot(inputs[i], w1) + bias1
        net2 = np.dot(net1, w2) + bias2

        output = [1 if net2[j] >= 0 else 0 for j in range(output_neurons)]
        outputs.append(output)

        if not np.array_equal(output, expected_outputs[i]):
            found = False
            break  # try again

    if found:
        break

print(f"\nNeural Network with {n} inputs, 1 hidden layer, and 2 outputs")
print(f"\nOutput matched expected results in {training_step} training step(s)\n")

print("Weight 1 matrix (Input -> Hidden) :")
print(w1)
print("\nWeight 2 matrix (Hidden -> Output) :")
print(w2)

for i in range(total_cases):
    print(f"Input: {inputs[i]} \t Expected: {expected_outputs[i]} \t Output: {outputs[i]}")


-----------------------------------------------------------
#SIGMOID,TANH,RELU
import numpy as np 

def sigmoid(x):
    return 1/(1+np.exp(-x))
def sigmoid_derivative(x):
    sx = sigmoid(x)
    return sx*(1-sx)
    
def relu(x):
    return np.maximum(0, x)

def relu_derivative(x):
    return (x > 0).astype(float)

def tanh(x):
    return np.tanh(x)

def tanh_derivative(x):
    return 1 - np.tanh(x)**2

def binary_cross_entropy(y_true,y_pred):
    epsilon=1e-8
    return -np.mean(y_true*np.log(y_pred+epsilon)+(1-y_true)*np.log((1-y_pred)+epsilon))
def generate_binary_inputs(n):
    total_cases = 2 ** n
    return np.array([[int(x) for x in format(i, f'0{n}b')] for i in range(total_cases)])


def train_network(inputs, expected_outputs, hidden1_neurons, hidden2_neurons, lr=0.1, epochs=10000):
    n_samples,n_features = inputs.shape

    W1 = np.random.randn(n_features, hidden1_neurons)
    B1 = np.zeros((1, hidden1_neurons))
    W2 = np.random.randn(hidden1_neurons, hidden2_neurons)
    B2 = np.zeros((1, hidden2_neurons))
    W3 = np.random.randn(hidden2_neurons, 1)
    B3 = np.zeros((1, 1))
    
    for epoch in range(epochs):
         # Forward pass
        Z1 = np.dot(inputs, W1) + B1
        A1 = sigmoid(Z1) #A1 = tanh(Z1) #A1 = relu(Z1)
        Z2 = np.dot(A1, W2) + B2
        A2 = sigmoid(Z2) #A2 = tanh(Z2) #A2 = relu(Z2)
        Z3 = np.dot(A2, W3) + B3
        A3 = sigmoid(Z3) #A3 = sigmoid(Z3) , A3 = sigmoid(Z3)
        loss = binary_cross_entropy(expected_outputs, A3)

        dZ3 = A3 - expected_outputs #dZ3 is the gradient of the loss with respect to Z3 (raw score before final sigmoid).
        dW3 = np.dot(A2.T, dZ3)# how many neurons contributed to error
        dB3 = np.sum(dZ3, axis=0, keepdims=True)

        dA2 = np.dot(dZ3, W3.T)
        dZ2 = dA2 * sigmoid_derivative(Z2) #dZ2 = dA2 * tanh_derivative(Z2) 
        dW2 = np.dot(A1.T, dZ2)
        dB2 = np.sum(dZ2, axis=0, keepdims=True)

        dA1 = np.dot(dZ2, W2.T)
        dZ1 = dA1 * sigmoid_derivative(Z1) #dZ1 = dA1 * tanh_derivative(Z1) 
        dW1 = np.dot(inputs.T, dZ1) 
        dB1 = np.sum(dZ1, axis=0, keepdims=True)

        W3 -= lr * dW3
        B3 -= lr * dB3
        W2 -= lr * dW2
        B2 -= lr * dB2
        W1 -= lr * dW1
        B1 -= lr * dB1

        if epoch % 1000 == 0 or epoch == epochs - 1:
            print(f"Epoch {epoch} | Loss: {loss:.6f}")
            
    # Final predictions
    final_output = (A3 > 0.5).astype(int)
    return final_output,W1,W2,W3

n = int(input("Enter the number of inputs"))
inputs = generate_binary_inputs(n)
expected_outputs = []
for row in inputs :
    output = int(input(f"Input:{row}-"))
    expected_outputs.append(output)
expected_outputs = np.array(expected_outputs).reshape(-1,1)

hidden1 = int(input("\nEnter number of neurons in Hidden Layer 1: "))
hidden2 = int(input("Enter number of neurons in Hidden Layer 2: "))
lr = float(input("Enter learning rate (e.g., 0.1): "))
epochs = int(input("Enter number of training epochs: "))

# ---- Training ----
predicted_output, W1, W2, W3 = train_network(inputs, expected_outputs,hidden1_neurons=hidden1 ,hidden2_neurons=hidden2,lr=lr,epochs=epochs)
# ---- Results ----
print("\nFinal predictions vs Expected:")
for i in range(len(inputs)):
    print(f"Input: {inputs[i]} \t Expected: {expected_outputs[i][0]} \t Predicted: {predicted_output[i][0]}")

---------------------------------------------------------
#NLP
!pip install textblob
import re
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
from textblob import TextBlob

# Download necessary NLTK datasets
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Function to read the file
def read_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()

# Function to clean text: Remove punctuation, numbers, and extra white spaces
def clean_text(text):
    text = re.sub(r'[^\w\s]', ' ', text)  # Remove punctuation/special characters
    text = re.sub(r'\d+', ' ', text)  # Remove numbers
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra spaces
    return text

# Function to correct spelling
def correct_spelling(words):
    return [str(TextBlob(w).correct()) if len(w) > 2 else w for w in words]

# def correct_spelling(words):
#     corrected_words = []
#     for w in words:
#         if len(w) > 2:
#             corrected_word = str(TextBlob(w).correct())
#             corrected_words.append(corrected_word)
#         else:
#             corrected_words.append(w)
#     return corrected_words

# Main function to process the text
def process_text(file_path):
    text = read_file(file_path)

    # Clean the text
    cleaned_text = clean_text(text)

    # Convert text to lowercase
    cleaned_text = cleaned_text.lower()

    # Tokenization
    words = word_tokenize(cleaned_text)

    # Remove stop words
    stop_words = set(stopwords.words('english'))
    filtered_words = [w for w in words if w not in stop_words]

    # Correct misspelled words
    corrected_words = correct_spelling(filtered_words)

    # Stemming
    stemmer = PorterStemmer()
    stemmed_words = [stemmer.stem(w) for w in corrected_words]

    # Lemmatization
    lemmatizer = WordNetLemmatizer()
    lemmatized_words = [lemmatizer.lemmatize(w) for w in corrected_words]

    # Generate trigrams after lemmatization
    trigrams = [' '.join(lemmatized_words[i:i+3]) for i in range(len(lemmatized_words) - 2)]

    return {
        "cleaned_text": cleaned_text,
        "tokenized_words": words,
        "filtered_words": filtered_words,
        "corrected_words": corrected_words,
        "stemmed_words": stemmed_words,
        "lemmatized_words": lemmatized_words,
        "trigrams": trigrams
    }

# Example usage
file_path = 'words.txt'  # Replace with your text file path
result = process_text(file_path)

# Displaying Results
print("Cleaned Text Preview:\n", result["cleaned_text"][:200])
print("\nTokenized Words:\n", result["tokenized_words"][:15])
print("\nFiltered Words (No Stop Words):\n", result["filtered_words"][:15])
print("\nCorrected Words:\n", result["corrected_words"][:15])
print("\nStemmed Words:\n", result["stemmed_words"][:15])
print("\nLemmatized Words:\n", result["lemmatized_words"][:15])
print("\nFirst 5 Trigrams:\n", "\n".join(result["trigrams"][:5]))

------------------------------------------
#GAME-NIM SUM
#WINNING

def nim_sum(piles):
    """Calculate the nim-sum (XOR of all piles)."""
    result = 0
    for pile in piles:
        result ^= pile
    return result

def computer_move(piles):
    """Computes the optimal move for the computer (always wins or draws)."""
    nim = nim_sum(piles)
    
    # If nim-sum is 0, the current player is at a disadvantage
    if nim == 0:
        # No optimal move, so the computer will just remove one object from the last pile.
        for i in range(len(piles)-1, -1, -1):
            if piles[i] > 0:
                piles[i] -= 1
                break
    else:
        # Otherwise, find the move that results in a Nim-Sum of 0.
        for i in range(len(piles)):
            target = piles[i] ^ nim  # The pile's new size after the move
            if target < piles[i]:
                piles[i] = target
                break
    return piles

def player_move(piles):
    """Player makes a move."""
    while True:
        try:
            pile = int(input("Choose a pile (0, 1, 2, ...): "))
            objects = int(input(f"How many objects to remove from pile {pile}? "))
            if 0 <= pile < len(piles) and 0 < objects <= piles[pile]:
                piles[pile] -= objects
                break
            else:
                print("Invalid move. Try again.")
        except ValueError:
            print("Invalid input. Try again.")
    return piles

def play_game():
    piles = [3, 4, 5]  # Example starting piles
    while True:
        print(f"Piles: {piles}")
        
        # Player's turn
        piles = player_move(piles)
        if sum(piles) == 0:
            print("Player wins!")
            break
        
        # Computer's turn
        piles = computer_move(piles)
        print(f"Computer's turn: {piles}")
        if sum(piles) == 0:
            print("Computer wins!")
            break
play_game()

------------------------------------------
#LOSING

def nim_sum(piles):
    """Calculate the nim-sum (XOR of all piles)."""
    result = 0
    for pile in piles:
        result ^= pile
    return result
def computer_move_lose(piles):
    """Computes the move for the computer (always loses or draws)."""
    nim = nim_sum(piles)
    
    # If nim-sum is 0, the current player is at a disadvantage
    if nim == 0:
        # No optimal move, just remove one object from the last pile.
        for i in range(len(piles)-1, -1, -1):
            if piles[i] > 0:
                piles[i] -= 1
                break
    else:
        # Play to ensure the Nim-Sum is not optimized.
        for i in range(len(piles)):
            if piles[i] > 1:
                piles[i] -= 1  # Simply remove one object (this leads to loss eventually)
                break
    return piles

def play_game_lose():
    piles = [3, 4, 5]  # Example starting piles
    while True:
        print(f"Piles: {piles}")
        
        # Player's turn
        piles = player_move(piles)
        if sum(piles) == 0:
            print("Player wins!")
            break
        
        # Computer's turn (always plays suboptimal, leads to loss or draw)
        piles = computer_move_lose(piles)
        print(f"Computer's turn: {piles}")
        if sum(piles) == 0:
            print("Computer wins!")
            break
play_game_lose()
